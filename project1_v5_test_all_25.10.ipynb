{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Data processed\n",
      "Data standardized\n",
      "Poly built\n",
      "poly logistic regression learning ongoing...\n",
      "inf\n",
      "1618097538989.2424\n",
      "inf\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margaux/Desktop/EPFL/MA1/Machine Learning/labs/01/ML_course/projects/project1/scripts/implementations.py:164: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n",
      "inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-66ff9bc04604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best method is '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m': score = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtest_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-66ff9bc04604>\u001b[0m in \u001b[0;36mtest_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     '''\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_methods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1/Machine Learning/labs/01/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mtest_methods\u001b[0;34m(y, tx, method)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'poly logistic regression learning ongoing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             w, loss = logistic_regression(\n\u001b[0;32m--> 632\u001b[0;31m                                 logistic_y_train, poly_tx_train, initial_w,max_iters, gamma)\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_logistic_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_tx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1/Machine Learning/labs/01/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current iteration={i}, loss={l}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         '''\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_logistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1/Machine Learning/labs/01/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mcompute_logistic_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_logistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;34m\"\"\"compute the gradient of loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;31m## ******************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/MA1/Machine Learning/labs/01/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;34m\"\"\"apply sigmoid function on t.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;31m## ******************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_logistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_main():\n",
    "    ''' TEST ALL RAW METHODS '''\n",
    "    \n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y, tx, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    methods = ['least_square_GD', \n",
    "               'least_square_SGD', \n",
    "               'least_squares', \n",
    "               'ridge_regression', \n",
    "               'logistic_regression', \n",
    "               'reg_logistic_regression']\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    scores.append(test_methods(y,tx,methods[0]))\n",
    "    scores.append(test_methods(y,tx,methods[1]))\n",
    "    scores.append(test_methods(y,tx,methods[2]))\n",
    "    scores.append(test_methods(y,tx,methods[3]))\n",
    "    scores.append(test_methods(y,tx,methods[4]))\n",
    "    scores.append(test_methods(y,tx,methods[5]))\n",
    "    \n",
    "    index = np.argmax(scores)\n",
    "    \n",
    "    print('Best method is ', methods[index], ': score = ', scores[index])\n",
    "\n",
    "test_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "degree: 4  lambda: 1e-12 -> RMSE  =  0.7402822368189568\n"
     ]
    }
   ],
   "source": [
    "def hyperparameters_main():\n",
    "    ''' FIND OPTIMAL PARAMETERS FOR RIDGE REGRESSION '''\n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y_train, tx_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    # Pre-processing of data \n",
    "    # -> delete nan and replace by mean column value\n",
    "    # -> replace outliers by low/high bound\n",
    "    processed_tx_train = process_data(tx_train)\n",
    "    \n",
    "    optimal_degree, optimal_lambda = find_optimal_hyperparameters(y_train, processed_tx_train)\n",
    "\n",
    "    print('optimal hyperparameters found:')\n",
    "    print('- degree = ', optimal_degree) \n",
    "    print('- lambda = ', optimal_lambda)\n",
    "  \n",
    "hyperparameters_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Data processed\n",
      "Hyperparameters optimized\n",
      "(250000, 645)\n",
      "(568238, 645)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    '''OPTIMAL METHOD COMPUTED\n",
    "    '''\n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y_train, tx_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    DATA_TEST_PATH = \"../data/test.csv\"\n",
    "    _, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    # Pre-processing of data \n",
    "    # -> delete nan and replace by mean column value\n",
    "    # -> replace outliers by low/high bound\n",
    "    processed_tx_train = process_data(tx_train)\n",
    "    processed_tx_test = process_data(tx_test)\n",
    "    \n",
    "    print('Data processed')\n",
    "    \n",
    "    optimal_degree = 6\n",
    "    optimal_lambda = 2.8942661247167517e-10\n",
    "    \n",
    "    print('Hyperparameters optimized')\n",
    "    \n",
    "    # Test optimized ridge regression with \n",
    "    # optimal degree = 6 and lambda = 2.8942661247167517e-10\n",
    "    # Build poly and add cross-terms\n",
    "    \n",
    "    print('Building training polynomial array ongoing...')\n",
    "    poly_tx_train = build_poly(processed_tx_train, optimal_degree)\n",
    "    cross_terms_tx_train = build_cross_terms(processed_tx_train)\n",
    "    final_tx_train = np.c_[poly_tx_train, cross_terms_tx_train]\n",
    "    print('shape of final_tx_train: ',np.shape(final_tx_train))\n",
    "    \n",
    "    print('Building testing polynomial array ongoing...')\n",
    "    poly_tx_test = build_poly(processed_tx_test, optimal_degree)\n",
    "    cross_terms_tx_test = build_cross_terms(processed_tx_test)\n",
    "    final_tx_test = np.c_[poly_tx_test, cross_terms_tx_test]\n",
    "    print('shape of final_tx_test: ', np.shape(final_tx_test))\n",
    "    \n",
    "    print('Ridge regression ongoing')\n",
    "    w, loss = ridge_regression(y_train, final_tx_train, optimal_lambda)\n",
    "    print('shape of weights: ',np.shape(w))\n",
    "    \n",
    "    return w, final_tx_test, ids_test\n",
    "\n",
    "w, tX_test, ids_test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"../data/submission009.csv\"\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_num_main():\n",
    "    \n",
    "    ws = []\n",
    "    tx_final = []\n",
    "    \n",
    "    for jet_num in range(0,4,1):\n",
    "        \n",
    "        tx_train,y_train = create_batch(jet_num,tx,y)\n",
    "        tx_test,_ = create_batch(jet_num,tx)\n",
    "        \n",
    "        # Pre-processing of data \n",
    "        # -> delete nan and replace by mean column value\n",
    "        # -> replace outliers by low/high bound\n",
    "        processed_tx_train = process_data(tx_train)\n",
    "        processed_tx_test = process_data(tx_test)\n",
    "\n",
    "        print('Data processed')\n",
    "\n",
    "        optimal_degree = 6\n",
    "        optimal_lambda = 2.8942661247167517e-10\n",
    "\n",
    "        print('Hyperparameters optimized')\n",
    "\n",
    "        # Test optimized ridge regression with \n",
    "        # optimal degree = 6 and lambda = 2.8942661247167517e-10\n",
    "        poly_tx_train = build_poly(processed_tx_train, optimal_degree)\n",
    "        poly_tx_test = build_poly(processed_tx_test, optimal_degree)\n",
    "        w, loss = ridge_regression(y_train, poly_tx_train, optimal_lambda)\n",
    "        \n",
    "        tx_final.append(poly_tx_test)\n",
    "        ws.append(w)\n",
    "    \n",
    "    w = np.concatenate(ws,0)\n",
    "    tx_test = np.concatenate(tx_final,0)\n",
    "    \n",
    "    return w, tx_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 1.]\n",
      " [1. 2. 3. 1.]\n",
      " [1. 2. 3. 1.]\n",
      " [1. 2. 3. 1.]]\n",
      "[[2. 3. 1. 6. 2. 3.]\n",
      " [2. 3. 1. 6. 2. 3.]\n",
      " [2. 3. 1. 6. 2. 3.]\n",
      " [2. 3. 1. 6. 2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "mattrix = np.ones((4,4))\n",
    "mattrix[:,1] = mattrix[:,1]*2\n",
    "mattrix[:,2] = mattrix[:,2]*3\n",
    "print(mattrix)\n",
    "new = build_cross_terms(mattrix)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
