{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "from data_manager import *\n",
    "from runners import *\n",
    "from plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test consol"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test consol allows to simulate all learning methods with any parameters (presented in forms of lists), any processing data tool and by spliting or cross validating the data\n",
    "\n",
    "Reminder for My_options (processing data):\n",
    "     nandel -> delete nan values (-999.)\n",
    "     nanmed -> replace -999. with mean\n",
    "     bound -> eliminate outliers\n",
    "     std -> standardize data set\n",
    "     prb -> change y into probability values\n",
    "     zerovar -> eliminate columns with no varinaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: % 65.53999999999999\n",
      "Score: % 65.53999999999999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data processing -> part you can play with\n",
    "My_options = ['nanmed', 'bound', 'std', 'prb']\n",
    "\n",
    "# If you use jets\n",
    "#jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "#y, tX = jets_y[3], jets_tX[3]\n",
    "\n",
    "#Split (split=True) or cross (split=False)\n",
    "split = False\n",
    "ratio = 0.8\n",
    "seed = 1\n",
    "\n",
    "\n",
    "# Parameters -> part you can play with\n",
    "# Every parameter needs to be in a list (if np.array write inside brackets por favor)\n",
    "degrees = []\n",
    "gammas = [np.logspace(-20, -10, 2)]\n",
    "lambdas = []\n",
    "method = logistic_regression\n",
    "\n",
    "# Gradient parameters, indicate if you are using a gradient method (True/False)\n",
    "Grad_method = True\n",
    "max_iter = 1000\n",
    "w_init = []\n",
    "\n",
    "'''Everything above can be modified'''\n",
    "#************************************************************************************************\n",
    "'''Everything under should not be modified'''\n",
    "\n",
    "y, tX = process_data(y, tX, My_options)\n",
    "y_tr, x_tr, y_te, x_te = split_data(y, tX, ratio, seed)\n",
    "grad = [Grad_method, w_init, max_iter]\n",
    "\n",
    "# Run-run-run\n",
    "if split:\n",
    "    weights, losses = optimization(y_tr, x_tr, method, degrees, gammas, lambdas, grad)\n",
    "else:\n",
    "    weights, losses = optimization_cross(y, tX, method, degrees, gammas, lambdas, grad)\n",
    "\n",
    "\n",
    "# Plot-plot-plot\n",
    "\n",
    "logistic = False \n",
    "\n",
    "if 'prb' in My_options:\n",
    "    logistic = True\n",
    "    \n",
    "if len(weights) == 1:\n",
    "    if len(degrees[0]) == 1:\n",
    "        x_te = build_poly(x_te, degrees[0][0])\n",
    "    test_score(y_te, x_te, weights[0])\n",
    "elif lambdas :\n",
    "    if len(lambdas[0]) == 1:\n",
    "        plot_my_values(weights, y_te, x_te, degrees, gammas, [], logistic)\n",
    "elif degrees : \n",
    "    if len(degrees[0]) == 1:\n",
    "        x_te = build_poly(x_te, degrees[0][0])\n",
    "        plot_my_values(weights, y_te, x_te, [], gammas, lambdas, logistic)\n",
    "else :\n",
    "    plot_my_values(weights, y_te, x_te, degrees, gammas, lambdas, logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "least square GD learning ongoing...\n",
      "Score: % 70.748\n",
      "least square SGD learning ongoing...\n",
      "Score: % 69.452\n",
      "least square learning ongoing...\n",
      "Score: % 74.688\n",
      "ridge learning ongoing...\n",
      "Score: % 74.688\n",
      "logistic regression learning ongoing...\n",
      "Score: % 75.1365\n",
      "reg logistic regression learning ongoing...\n",
      "Score: % 75.09\n",
      "Best method is  logistic_regression : score =  0.751365\n"
     ]
    }
   ],
   "source": [
    "def test_main():\n",
    "    ''' TEST ALL RAW METHODS '''\n",
    "    \n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y, tx, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    methods = ['least_square_GD', \n",
    "               'least_square_SGD', \n",
    "               'least_squares', \n",
    "               'ridge_regression', \n",
    "               'logistic_regression', \n",
    "               'reg_logistic_regression']\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for method in methods:\n",
    "        scores.append(test(y, tx, method))\n",
    "\n",
    "    \n",
    "    index = np.argmax(scores)   \n",
    "    print('Best method is ', methods[index], ': score = ', scores[index])\n",
    "    \n",
    "test_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jet values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma =  1e-12\n",
      "(250000, 181) (99913, 153)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 250000 and the array at index 1 has size 99913",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-d0a8f77e166e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgamma_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mjet_ski\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-d0a8f77e166e>\u001b[0m in \u001b[0;36mjet_ski\u001b[0;34m(y, tX, methods, parameters)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mjets_tX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_tX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_terms_tx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfinal_tX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjets_tX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_terms_tx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_tX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 250000 and the array at index 1 has size 99913"
     ]
    }
   ],
   "source": [
    "def jet_ski(y, tX, methods, parameters):\n",
    "    ratio = 0.8\n",
    "    seed = 1\n",
    "    \n",
    "    pred = []\n",
    "    Y =[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "    \n",
    "    My_options = ['nanmed', 'bound', 'zerovar','std']\n",
    "    \n",
    "    for ind in range(len(jets_y)):\n",
    "        jets_y[ind], jets_tX[ind] = process_data(jets_y[ind], jets_tX[ind], My_options)\n",
    "        cross_terms_tx_train = build_cross_terms(jets_tX[ind])\n",
    "        jets_tX[ind] = build_poly(tX,6)\n",
    "        print(jets_tX[ind].shape, cross_terms_tx_train.shape)\n",
    "        final_tX = np.c_[jets_tX[ind], cross_terms_tx_train]\n",
    "        \n",
    "        y_tr, x_tr, y_te, x_te = split_data(jets_y[ind], final_tX, ratio, seed)\n",
    "       \n",
    "        #w_initial = np.zeros(x_tr.shape[1])\n",
    "        param = [y_tr, x_tr]\n",
    "        P = param + parameters\n",
    "\n",
    "        w,loss = test_methods(methods, P)\n",
    "        \n",
    "        #pred_train = predict(x_tr, w)\n",
    "        pred_test = predict(x_te, w)\n",
    "        print(\"index\", ind)\n",
    "        print(\"validation accuracy : \", np.sum(pred_test==y_te)/pred_test.shape[0])\n",
    "        \n",
    "        pred.append(pred_test)\n",
    "        Y.append(y_te)\n",
    "    \n",
    "    pred =np.concatenate(pred, 0)\n",
    "    Y = np.concatenate(Y,0)\n",
    "    \n",
    "    print(\"total accuracy :\", np.sum(pred==Y)/pred.shape[0])\n",
    "    \n",
    "#max_iters = 5000\n",
    "#gamma = 2.89e-10\n",
    "gammas = np.logspace(-12, -8, 10)\n",
    "\n",
    "   \n",
    "#jet_ski(y, tX, ridge_regression, parameters)\n",
    "    \n",
    "\n",
    "for gamma_ in gammas: \n",
    "    print(\"gamma = \", gamma_)\n",
    "    parameters = [gamma_]\n",
    "    jet_ski(y, tX, ridge_regression, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing jet 0\n",
      "Analyzing jet 1\n",
      "Analyzing jet 2\n",
      "Analyzing jet 3\n",
      "total accuracy : 0.3039430661096231\n"
     ]
    }
   ],
   "source": [
    "def jet_ski(y, tX,ids,y_test,tX_test,ids_test, methods, parameters):\n",
    "    ratio = 0.8\n",
    "    seed = 1\n",
    "    \n",
    "    pred = []\n",
    "    id_t =[]\n",
    "    Y =[]\n",
    "    tX = build_poly(tX,2)\n",
    "    tX_test = build_poly(tX_test,2)\n",
    "    \n",
    "    \n",
    "    jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "    jets_y_test, jets_tX_test, id_test = cat_variables(y_test, tX_test, ids_test)\n",
    "    \n",
    "    \n",
    "    My_options = ['nanmed', 'bound', 'zerovar','std']\n",
    "    \n",
    "    for ind in range(len(jets_y)):\n",
    "        print('Analyzing jet {}'.format(ind))\n",
    "        jets_y[ind], jets_tX[ind] = process_data(jets_y[ind], jets_tX[ind], My_options)\n",
    "        jets_y_test[ind], jets_tX_test[ind] = process_data(jets_y_test[ind], jets_tX_test[ind], My_options)\n",
    "\n",
    "\n",
    "        cross_terms_tx_train = build_cross_terms(jets_tX[ind])\n",
    "        final_tX_train = np.c_[jets_tX[ind], cross_terms_tx_train]\n",
    "        \n",
    "        cross_terms_tx_test = build_cross_terms(jets_tX_test[ind])\n",
    "        final_tX_test = np.c_[jets_tX_test[ind], cross_terms_tx_test]\n",
    "\n",
    "        param = [jets_y[ind], final_tX_train]\n",
    "        P = param + parameters\n",
    "\n",
    "        w,loss = test_methods(methods, P)\n",
    "        \n",
    "        pred_test = predict(final_tX_test,w)\n",
    "        \n",
    "        pred.append(pred_test)\n",
    "        id_t.append(id_test[ind])\n",
    "        \n",
    "        Y.append(jets_y_test[ind])\n",
    "\n",
    " \n",
    "    \n",
    "    pred =np.concatenate(pred, 0)\n",
    "    id_t =np.concatenate(id_t,0)\n",
    "    Y =np.concatenate(Y,0)\n",
    "\n",
    "    print(\"total accuracy :\", np.sum(pred==Y)/pred.shape[0])\n",
    "\n",
    "\n",
    "    OUTPUT_PATH = \"submissionfloflo.csv\"    \n",
    "    \n",
    "    create_csv_submission(id_t, pred, OUTPUT_PATH)\n",
    "#max_iters = 5000\n",
    "gamma = 2.89e-10\n",
    "\n",
    "   \n",
    "parameters = [gamma]\n",
    "\n",
    "\n",
    "jet_ski(y, tX,ids,y_test,tX_test,ids_test, ridge_regression, parameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
