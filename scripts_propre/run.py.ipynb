{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "from data_manager import *\n",
    "from runners import *\n",
    "from plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test consol"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test consol allows to simulate all learning methods with any parameters (presented in forms of lists), any processing data tool and by spliting or cross validating the data\n",
    "\n",
    "Reminder for My_options (processing data):\n",
    "     nandel -> delete nan values (-999.)\n",
    "     nanmed -> replace -999. with mean\n",
    "     bound -> eliminate outliers\n",
    "     std -> standardize data set\n",
    "     prb -> change y into probability values\n",
    "     zerovar -> eliminate columns with no varinaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runing with two types of parameter...\n",
      "runing degree 1\n",
      "runing degree 2\n",
      "runing degree 3\n",
      "runing degree 4\n",
      "runing degree 5\n",
      "runing degree 6\n",
      "runing degree 7\n",
      "runing degree 8\n",
      "runing degree 9\n",
      "Score: % 72.546808030679\n",
      "Score: % 81.3670200766975\n",
      "Score: % 81.23167155425219\n",
      "Score: % 84.07399052560342\n",
      "Score: % 84.27701330927138\n",
      "Score: % 84.57026844123618\n",
      "Score: % 84.52515226708776\n",
      "Score: % 84.79584931197834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: % 84.81840739905256\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data processing -> part you can play with\n",
    "My_options = ['nanmed', 'bound', 'zerovar']\n",
    "\n",
    "# If you use jets\n",
    "jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "y, tX = jets_y[3], jets_tX[3]\n",
    "\n",
    "#Split (split=True) or cross (split=False)\n",
    "split = True\n",
    "ratio = 0.8\n",
    "seed = 1\n",
    "\n",
    "\n",
    "# Parameters -> part you can play with\n",
    "# Every parameter needs to be in a list (if np.array write inside brackets por favor)\n",
    "degrees = [range(1, 10)]\n",
    "gammas = []\n",
    "lambdas = [[1.1253355826007645e-10]]\n",
    "method = ridge_regression\n",
    "\n",
    "# Gradient parameters, indicate if you are using a gradient method (True/False)\n",
    "Grad_method = False\n",
    "max_iter = 1000\n",
    "w_init = []\n",
    "\n",
    "'''Everything above can be modified'''\n",
    "#************************************************************************************************\n",
    "'''Everything under should not be modified'''\n",
    "\n",
    "y, tX = process_data(y, tX, My_options)\n",
    "y_tr, x_tr, y_te, x_te = split_data(y, tX, ratio, seed)\n",
    "grad = [Grad_method, w_init, max_iter]\n",
    "\n",
    "# Run-run-run\n",
    "if split:\n",
    "    weights, losses = optimization(y_tr, x_tr, method, degrees, gammas, lambdas, grad)\n",
    "else:\n",
    "    weights, losses = optimization_cross(y, tX, method, degrees, gammas, lambdas, grad)\n",
    "\n",
    "    \n",
    "\n",
    "# Plot-plot-plot\n",
    "\n",
    "logistic = False \n",
    "\n",
    "if 'prb' in My_options:\n",
    "    logistic = True\n",
    "    \n",
    "if len(weights) == 1:\n",
    "    if len(degrees[0]) == 1:\n",
    "        x_te = build_poly(x_te, degrees[0][0])\n",
    "    test_score(y_te, x_te, weights[0])\n",
    "elif lambdas :\n",
    "    if len(lambdas[0]) == 1:\n",
    "        plot_my_values(weights, y_te, x_te, degrees, gammas, [], logistic)\n",
    "elif degrees : \n",
    "    if len(degrees[0]) == 1:\n",
    "        x_te = build_poly(x_te, degrees[0][0])\n",
    "        plot_my_values(weights, y_te, x_te, [], gammas, lambdas, logistic)\n",
    "else :\n",
    "    plot_my_values(weights, y_te, x_te, degrees, gammas, lambdas, logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "least square GD learning ongoing...\n",
      "Score: % 70.748\n",
      "least square SGD learning ongoing...\n",
      "Score: % 69.452\n",
      "least square learning ongoing...\n",
      "Score: % 74.688\n",
      "ridge learning ongoing...\n",
      "Score: % 74.688\n",
      "logistic regression learning ongoing...\n",
      "Score: % 75.1365\n",
      "reg logistic regression learning ongoing...\n",
      "Score: % 75.09\n",
      "Best method is  logistic_regression : score =  0.751365\n"
     ]
    }
   ],
   "source": [
    "def test_main():\n",
    "    ''' TEST ALL RAW METHODS '''\n",
    "    \n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y, tx, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    methods = ['least_square_GD', \n",
    "               'least_square_SGD', \n",
    "               'least_squares', \n",
    "               'ridge_regression', \n",
    "               'logistic_regression', \n",
    "               'reg_logistic_regression']\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for method in methods:\n",
    "        scores.append(test(y, tx, method))\n",
    "\n",
    "    \n",
    "    index = np.argmax(scores)   \n",
    "    print('Best method is ', methods[index], ': score = ', scores[index])\n",
    "    \n",
    "test_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reminder for My_options (processing data):\n",
    "     nandel -> delete nan values (-999.)\n",
    "     nanmed -> replace -999. with mean\n",
    "     bound -> eliminate outliers\n",
    "     std -> standardize data set\n",
    "     prb -> change y into probability values\n",
    "     zerovar -> eliminate columns with no varinaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Selection of jet 0\n",
      "Data processed\n",
      "best for degree  5  lambda: 1e-12 -> RMSE  =  0.680278061886013\n",
      "best for degree  6  lambda: 1e-12 -> RMSE  =  0.6793823605223961\n",
      "best for degree  7  lambda: 1e-12 -> RMSE  =  0.6782717805724462\n",
      "best for degree  8  lambda: 2.571913809059347e-12 -> RMSE  =  0.6780140644580992\n",
      "Selection of jet 1\n",
      "Data processed\n",
      "best for degree  5  lambda: 2.571913809059347e-12 -> RMSE  =  0.7571239649417154\n",
      "best for degree  6  lambda: 7.443803013251697e-10 -> RMSE  =  0.7517342195221864\n",
      "best for degree  7  lambda: 7.443803013251697e-10 -> RMSE  =  0.7507742210248669\n",
      "best for degree  8  lambda: 1e-12 -> RMSE  =  0.7496615590124668\n",
      "Selection of jet 2\n",
      "Data processed\n",
      "best for degree  5  lambda: 1.9144819761699535e-09 -> RMSE  =  0.7106451707154525\n",
      "best for degree  6  lambda: 1.1253355826007645e-10 -> RMSE  =  0.7057623927378783\n",
      "best for degree  7  lambda: 1e-12 -> RMSE  =  0.7045770688251414\n",
      "best for degree  8  lambda: 1e-12 -> RMSE  =  0.7032418141432465\n",
      "Selection of jet 3\n",
      "Data processed\n",
      "best for degree  5  lambda: 1.1937766417144357e-09 -> RMSE  =  0.7198628216101401\n",
      "best for degree  6  lambda: 1.7012542798525856e-11 -> RMSE  =  0.7065798410614118\n",
      "best for degree  7  lambda: 1e-12 -> RMSE  =  0.7052526102122008\n",
      "best for degree  8  lambda: 1e-12 -> RMSE  =  0.7008581897186767\n"
     ]
    }
   ],
   "source": [
    "# Load train and test data\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "y, tx, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print('Data loaded')\n",
    "\n",
    "jets_y, jets_tX, _ = cat_variables(y, tx, ids)\n",
    "\n",
    "for i in range(len(jets_y)):\n",
    "    \n",
    "    print('Selection of jet', i)\n",
    "    \n",
    "    My_options = ['nanmed', 'bound', 'zerovar']\n",
    "    y, processed_tx_train = process_data(jets_y[i], jets_tX[i], My_options)\n",
    "    print('Data processed')\n",
    "\n",
    "    # Find the optimal parameters for ridge regression\n",
    "    optimal_degree, optimal_lambda = optimal_hyperparameters(y, processed_tx_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy test for the best model : ridge-regression with poly/cross-term/Jet values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet number :  0\n",
      "validation accuracy :  0.8552269429014663\n",
      "jet number :  1\n",
      "validation accuracy :  0.8110129602166484\n",
      "jet number :  2\n",
      "validation accuracy :  0.8401151250496228\n",
      "jet number :  3\n",
      "validation accuracy :  0.8490863974734942\n",
      "total accuracy : 0.8379232415351693\n"
     ]
    }
   ],
   "source": [
    "def jet_accuracy_test(y, tX, methods, parameters):\n",
    "    ratio = 0.8\n",
    "    seed = 1\n",
    "    \n",
    "    pred = []\n",
    "    Y =[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "    \n",
    "    My_options = ['nanmed', 'bound', 'zerovar']\n",
    "    \n",
    "    for ind in range(len(jets_y)):\n",
    "        jets_y[ind], jets_tX[ind] = process_data(jets_y[ind], jets_tX[ind], My_options)\n",
    "        final_tX = np.c_[build_poly(jets_tX[ind],degres[ind]), build_cross_terms(jets_tX[ind])]\n",
    "     \n",
    "        \n",
    "        y_tr, x_tr, y_te, x_te = split_data(jets_y[ind], final_tX, ratio, seed)\n",
    "       \n",
    "        \n",
    "        param = [y_tr, x_tr,gammas[ind]]\n",
    "\n",
    "        w,loss = test_methods(methods, param)\n",
    "        \n",
    "        pred_test = predict(x_te, w)\n",
    "        print(\"jet number : \", ind)\n",
    "        print(\"validation accuracy : \", np.sum(pred_test==y_te)/pred_test.shape[0])\n",
    "        \n",
    "        pred.append(pred_test)\n",
    "        Y.append(y_te)\n",
    "    \n",
    "    pred =np.concatenate(pred, 0)\n",
    "    Y = np.concatenate(Y,0)\n",
    "    \n",
    "    print(\"total accuracy :\", np.sum(pred==Y)/pred.shape[0])\n",
    "    \n",
    "\n",
    "gammas = [1e-12,7.443803013251697e-10,1.1253355826007645e-10,1.7012542798525856e-11]\n",
    "degres = [6,7,6,6]\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "parameters = gammas\n",
    "jet_accuracy_test(y, tX, ridge_regression, parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission of prediction with the best model : ridge-regresion with poly/cross-term/jet values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing jet 0\n",
      "Analyzing jet 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-b573b4a69a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-b573b4a69a15>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(y, tX, ids, y_test, tX_test, ids_test, methods, parameters)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#construction of the final features containing polynomiale features and cross-terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfinal_tX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_tX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_cross_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_tX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mfinal_tX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_tX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdegres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_cross_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjets_tX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#parameters token by the chosen method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EPFL/Master/project1/ML_cortana/scripts_propre/helpers.py\u001b[0m in \u001b[0;36mbuild_cross_terms\u001b[0;34m(tx)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mcross_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcross_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(y, tX,ids,y_test,tX_test,ids_test, methods, parameters):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #load datas \n",
    "    DATA_TRAIN_PATH = '../data/train.csv' \n",
    "    y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "    DATA_TEST_PATH = '../data/test.csv' \n",
    "    y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "    #best parameters found from learning\n",
    "    gammas = [1e-12,7.443803013251697e-10,1.1253355826007645e-10,1.7012542798525856e-11]\n",
    "    degres = [6,7,6,6]\n",
    "    \n",
    "    \n",
    "    pred = []\n",
    "    id_t =[]\n",
    "    \n",
    "    #create jet_num\n",
    "    jets_y, jets_tX, _ = cat_variables(y, tX, ids)\n",
    "    jets_y_test, jets_tX_test, id_test = cat_variables(y_test, tX_test, ids_test)\n",
    "    \n",
    "    #pre-processing options chosen\n",
    "        #convert nan values with median\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "    My_options = ['nanmed', 'bound', 'zerovar','std']\n",
    "    \n",
    "    #iteration in each jet_num batch\n",
    "    for ind in range(len(jets_y)):\n",
    "        print('Analyzing jet {}'.format(ind))\n",
    "        \n",
    "        #pre-process data (train and test)\n",
    "        jets_y[ind], jets_tX[ind] = process_data(jets_y[ind], jets_tX[ind], My_options)\n",
    "        jets_y_test[ind], jets_tX_test[ind] = process_data(jets_y_test[ind], jets_tX_test[ind], My_options)\n",
    "\n",
    "        #construction of the final features containing polynomiale features and cross-terms\n",
    "        final_tX_train = np.c_[build_poly(jets_tX[ind],degres[ind]), build_cross_terms(jets_tX[ind])]\n",
    "        final_tX_test = np.c_[build_poly(jets_tX_test[ind],degres[ind]), build_cross_terms(jets_tX_test[ind])]\n",
    "\n",
    "        #parameters token by the chosen method\n",
    "        param = [jets_y[ind], final_tX_train, gammas[ind]]\n",
    "       \n",
    "        #create weights and losses\n",
    "        w,loss = test_methods(methods, param)\n",
    "        \n",
    "        #creation of predictions\n",
    "        pred_test = predict(final_tX_test,w)\n",
    "        \n",
    "        #lists of prediction and ids for each jet batch\n",
    "        pred.append(pred_test)\n",
    "        id_t.append(id_test[ind])\n",
    "\n",
    "\n",
    " \n",
    "    # concatenation lists of ids and predictions for each jet batch in a single well arranged array\n",
    "    pred =np.concatenate(pred, 0)\n",
    "    id_t =np.concatenate(id_t,0)\n",
    "\n",
    "\n",
    "    #submission\n",
    "    OUTPUT_PATH = \"submissionfloflolog.csv\"    \n",
    "    create_csv_submission(id_t, pred, OUTPUT_PATH)\n",
    "    print('Submission saved as ', OUTPUT_PATH)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "main(y, tX,ids,y_test,tX_test,ids_test, ridge_regression, parameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
