{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Data processed\n",
      "Hyperparameters optimized\n",
      "[ 2.31172092e+02  3.23351487e-01 -9.85452875e-03  1.33853659e-04\n",
      " -8.95087571e-07  2.89337248e-09 -3.61959575e-12  6.17387451e+01\n",
      " -6.63330866e-04  3.27251619e-04 -1.58296239e-05  2.06483651e-07\n",
      " -1.04951277e-09  1.88210524e-12  6.19838251e+00  3.95012443e-03\n",
      " -2.32629515e-03  6.82961528e-05 -8.02082255e-07  4.16699626e-09\n",
      " -7.97719829e-12  1.25151937e+01 -9.22009827e-03  2.94684858e-04\n",
      " -4.30120477e-06  3.60238673e-08 -1.60951507e-10  2.96763423e-13\n",
      " -1.02464851e+01 -1.19361606e+00  1.52738120e+00 -1.07579403e+00\n",
      "  4.07353941e-01 -7.48054873e-02  5.23474343e-03 -4.90186961e+01\n",
      "  6.01775106e-03 -9.41703320e-05  4.48791362e-07 -9.77647473e-10\n",
      "  1.00016213e-12 -3.88959939e-16 -6.74172708e+00 -4.28960950e-02\n",
      " -5.29219910e-03  5.81826283e-03 -9.25795804e-04 -5.10732110e-04\n",
      " -2.07950969e-05 -1.02462207e+01 -1.22731930e+01  1.99899999e+01\n",
      " -1.45066415e+01  5.38103834e+00 -9.94983758e-01  7.27684940e-02\n",
      " -1.01849967e+01  2.01385847e-02 -1.71595501e-03  5.12926847e-05\n",
      " -4.47263426e-07 -3.98160656e-09  6.01998331e-11 -1.02469325e+01\n",
      " -3.20597758e-02  4.17199655e-04 -2.54006945e-06  8.03683807e-09\n",
      " -1.30156684e-11  8.61035368e-15 -1.02399441e+01 -1.35325925e+00\n",
      "  2.99939678e+00 -3.03215182e+00  1.52638336e+00 -3.72753829e-01\n",
      "  3.52251958e-02 -1.02462489e+01 -8.37178388e-02  1.17060216e-01\n",
      "  2.07749907e-01 -1.95063970e-02 -6.89618106e-02 -1.48001385e-02\n",
      " -1.02461960e+01  7.70161069e-02 -3.06397086e+00  1.50289969e+01\n",
      " -2.51181005e+01  1.76445825e+01 -4.18797016e+00 -1.02462479e+01\n",
      "  1.20440674e-02  3.24014111e-04 -8.21403363e-06  1.76420829e-07\n",
      " -2.95946842e-09  1.78483944e-11 -1.02462304e+01  4.08172666e-04\n",
      "  9.07326333e-03 -1.20296746e-03 -1.25485197e-02  2.01153753e-04\n",
      "  1.35609134e-03 -1.02460453e+01 -3.80658979e-03 -2.63184007e-03\n",
      "  1.16379021e-03  4.50730914e-05 -8.78835972e-05  2.36261827e-05\n",
      " -1.02460397e+01 -4.45170021e-01  2.63379418e-02 -7.55526373e-04\n",
      "  1.13711343e-05 -8.63322624e-08  2.61022813e-10 -1.02460449e+01\n",
      " -1.61771175e-03 -2.67977063e-02  7.25496977e-04 -3.35240854e-03\n",
      " -1.48967940e-04  5.06439774e-04 -1.02461472e+01 -3.86907893e-04\n",
      "  4.68706503e-05  8.88586435e-04 -2.63620341e-04 -1.13345052e-04\n",
      "  2.60319695e-05 -1.02461706e+01 -2.65641816e-02  1.43237746e-03\n",
      " -3.93853342e-05  5.57028973e-07 -3.87926259e-09  1.05999647e-11\n",
      " -1.02461697e+01 -7.99907029e-04 -2.92872740e-03  3.15045671e-04\n",
      "  1.22595030e-03 -2.55659742e-05 -1.09414441e-04 -1.02461696e+01\n",
      "  4.57265573e-03 -4.48502320e-05  3.24956321e-07 -1.37372852e-09\n",
      "  2.77447399e-12 -2.08943477e-15 -1.02461528e+01  4.15810279e-03\n",
      "  2.21720998e-03 -4.06520464e-03 -1.61202142e-02 -8.18544718e-03\n",
      "  4.05509319e-03 -1.02462595e+01  8.12061716e-03  1.10528921e-04\n",
      " -4.41088159e-06  4.94779414e-08 -2.43620378e-10  4.49668744e-13\n",
      " -1.02462594e+01 -2.87781641e-04  6.08513291e-02 -1.41112520e-03\n",
      " -8.06729929e-03  2.31495000e-04  8.21947949e-04 -1.02462598e+01\n",
      " -6.10529831e-03  4.11019923e-04  1.39019583e-03 -8.39336582e-05\n",
      " -6.41575978e-05  4.96956184e-06 -1.02453107e+01 -9.64984820e-01\n",
      "  4.69848810e-02 -1.17241702e-03  1.59327441e-05 -1.12099528e-07\n",
      "  3.19584849e-10 -1.02452868e+01 -4.67616184e-03  8.97385502e-02\n",
      "  2.31174684e-03 -2.73043649e-02 -1.14096548e-04  4.26738609e-03\n",
      " -1.02452088e+01  3.69910573e-03 -3.38829983e-02 -7.64288258e-03\n",
      "  1.55770123e-02  1.67593364e-03 -2.12279479e-03 -1.02452088e+01\n",
      "  2.65617404e-03 -1.18014643e-04  1.53630096e-06 -8.57200481e-09\n",
      "  2.22440556e-11 -2.20699788e-14]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # Load train and test data\n",
    "    DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "    y_train, tx_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "    \n",
    "    DATA_TEST_PATH = \"../data/test.csv\"\n",
    "    _, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    \n",
    "    \n",
    "    ''' only for testing\n",
    "    #Split data for learning\n",
    "    ratio = 0.8\n",
    "    seed = 1\n",
    "    tx_train, tx_test, y_train, y_test = split_data(tx, y, ratio, seed)\n",
    "    '''\n",
    "    \n",
    "    # Pre-processing of data -> delete nan and replace by mean column value\n",
    "    processed_tx_train = process_data(tx_train)\n",
    "    processed_tx_test = process_data(tx_test)\n",
    "    \n",
    "    print('Data processed')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # Standardize data (needed for GD, LGD)\n",
    "    standardized_tx_train, mean_tx_train, std_tx_train = standardize(processed_tx_train)\n",
    "    standardized_tx_test, _, _ = standardize(processed_tx_test, mean_tx_train, std_tx_train)\n",
    "    \n",
    "    print('Data standardized')\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Tune hyperparameters\n",
    "    degrees = range(6, 7)\n",
    "    lambdas = np.logspace(-12, 0, 2)\n",
    "    k_fold = 10\n",
    "    min_loss_test = 10e6\n",
    "    #optimal_degree, optimal_lambda = find_optimal_hyperparameters(y_train, processed_tx_train, y_test, processed_tx_test, degrees, lambdas, k_fold)\n",
    "    optimal_degree = 6\n",
    "    optimal_lambda = 2.8942661247167517e-10\n",
    "    \n",
    "    print('Hyperparameters optimized')\n",
    "            \n",
    "    '''    \n",
    "    \n",
    "    # Parameters and Initialization\n",
    "    initial_w = np.ones(processed_tx_train.shape[1])\n",
    "    max_iters = 4000\n",
    "    gamma = 0.003 # optimal found by testing...\n",
    "    batch_size = 1\n",
    "    lambda_ = 10e-5\n",
    "    \n",
    "    # Test least square GD\n",
    "    # w, loss = least_squares_GD(y_train, standardized_tx_train, initial_w, max_iters, gamma)\n",
    "    \n",
    "    # Test least square SGD\n",
    "    # w, loss = least_squares_SGD(y_train, standardized_tx_train, initial_w, batch_size, max_iters, gamma)\n",
    "    \n",
    "    # Test least square with normal equations\n",
    "    # w, loss = least_squares(y_train, processed_tx_train)\n",
    "    \n",
    "    # Test ridge regression\n",
    "    w, loss = ridge_regression(y_train, tx_train, lambda_)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Test optimized ridge regression with optimal degree = 6 and lambda = 2.8942661247167517e-10\n",
    "    poly_tx_train = build_poly(processed_tx_train, optimal_degree)\n",
    "    poly_tx_test = build_poly(processed_tx_test, optimal_degree)\n",
    "    \n",
    "    print('Polynomial data built')\n",
    "    \n",
    "    w, loss = ridge_regression(y_train, poly_tx_train, optimal_lambda)\n",
    "    \n",
    "    print(w)\n",
    "    \n",
    "    # test_score(y_test, standardized_tx_test, w) # only for least_square GD and SGD\n",
    "    # test_score(y_test, poly_tx_test, w)\n",
    "    \n",
    "    \n",
    "    return w, poly_tx_test, ids_test\n",
    "\n",
    "w, tX_test, ids_test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"../data/submission007.csv\"\n",
    "#y_pred = predict_labels(weights, tX_test)\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "1e-12\n"
     ]
    }
   ],
   "source": [
    "print(degree)\n",
    "print(lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
